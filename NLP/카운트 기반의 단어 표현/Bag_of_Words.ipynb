{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled15.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "id": "lirQTqMFmuo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1AFmNA7AbvZJ"
      },
      "outputs": [],
      "source": [
        "from konlpy.tag import Okt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "okt = Okt()\n",
        "\n",
        "def build_bag_of_words(document):\n",
        "  # 데이터 전처리 및 형태소 분석\n",
        "  document = document.replace('?','')\n",
        "  tokenized_document = okt.morphs(document)\n",
        "\n",
        "  word_to_index = {}\n",
        "  bow = []\n",
        "\n",
        "  for word in tokenized_document:\n",
        "    if word not in word_to_index.keys():\n",
        "      word_to_index[word] = len(word_to_index)\n",
        "      # Bow를 기본값으로 설정\n",
        "      bow.insert(len(word_to_index) - 1, 1)\n",
        "    else:\n",
        "      # 재등장하는 단어의 인덱스\n",
        "      index = word_to_index.get(word)\n",
        "      # 재등장한 단어는 해당하는 인덱스의 위치에 1을 더한다\n",
        "      bow[index] = bow[index] + 1\n",
        "  return word_to_index, bow"
      ],
      "metadata": {
        "id": "4efFOFdFm0Yz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"어제저녁은 떡볶이를 먹었는데 오늘 저녁은 뭐를 먹을까?\"\n",
        "vocab, bow = build_bag_of_words(text)\n",
        "print('vocabulary :', vocab)\n",
        "print('bag of words vector :', bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gktJlUL9nDeA",
        "outputId": "5a0f3541-4670-41e9-8158-85f8ab9c40b2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocabulary : {'어제': 0, '저녁': 1, '은': 2, '떡볶이': 3, '를': 4, '먹었는데': 5, '오늘': 6, '뭐': 7, '먹을까': 8}\n",
            "bag of words vector : [1, 2, 2, 1, 2, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CounterVectorizer 클래스로 Bow 만들기"
      ],
      "metadata": {
        "id": "AC6kiFluypXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = ['you know I want your love. because I love you.']\n",
        "vector = CountVectorizer()\n",
        "\n",
        "# 코퍼스로부터 각 단어의 빈도수를 기록\n",
        "print('bag og words vector :', vector.fit_transform(corpus).toarray())\n",
        "\n",
        "# 각 단어의 인덱스가 어떻게 부여되었는지를 출력\n",
        "print('vocavulary :', vector.vocabulary_)\n",
        "\n",
        "# Countervectorize는 길이가 2 이상인 문자만 토큰으로 인식\n",
        "# 띄어쓰기만을 기준으로 단어를 자른다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01o6hes7ytU4",
        "outputId": "ed2cb0a0-03ac-490b-a22b-e473136b6a4b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bag og words vector : [[1 1 2 1 2 1]]\n",
            "vocavulary : {'you': 4, 'know': 1, 'want': 3, 'your': 5, 'love': 2, 'because': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 불용어를 제거한 Bow"
      ],
      "metadata": {
        "id": "UVfC9TmTzfRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fZ6ehFBzfW6",
        "outputId": "b25fcc44-627d-4793-8cf5-b3e87d3a8689"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"Family is not an important thing. It's everything.\"]\n",
        "vect = CountVectorizer(stop_words=[\"the\", \"a\", \"an\", \"is\", \"not\"])\n",
        "# 불용어 직접 정의\n",
        "print('bag of words vector :',vect.fit_transform(text).toarray())\n",
        "print('vocabulary :',vect.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKaVCNrzzw3r",
        "outputId": "73e71db2-84f2-4418-8b7b-a25898cee0e9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bag of words vector : [[1 1 1 1 1]]\n",
            "vocabulary : {'family': 1, 'important': 2, 'thing': 4, 'it': 3, 'everything': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"Family is not an important thing. It's everything.\"]\n",
        "vect = CountVectorizer(stop_words=\"english\")\n",
        "# CountVectorizer에서 제공하는 불용어 사용\n",
        "print('bag of words vector :',vect.fit_transform(text).toarray())\n",
        "print('vocabulary :',vect.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpEBTXD8z54W",
        "outputId": "bf110879-9ff1-4a7f-e013-0fbc4cd3b1df"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bag of words vector : [[1 1 1]]\n",
            "vocabulary : {'family': 0, 'important': 1, 'thing': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"Family is not an important thing. It's everything.\"]\n",
        "stop_words = stopwords.words(\"english\")\n",
        "vect = CountVectorizer(stop_words=stop_words)\n",
        "# nltk에서 지원하는 불용어 사용\n",
        "print('bag of words vector :',vect.fit_transform(text).toarray()) \n",
        "print('vocabulary :',vect.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwUZjXgA0Byp",
        "outputId": "31770f8a-a3df-4034-b855-01174f16b6cf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bag of words vector : [[1 1 1 1]]\n",
            "vocabulary : {'family': 1, 'important': 2, 'thing': 3, 'everything': 0}\n"
          ]
        }
      ]
    }
  ]
}